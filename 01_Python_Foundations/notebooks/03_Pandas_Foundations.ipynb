{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88cf12e-9352-428d-908c-7e09a5b81d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Completed Pages:----\n",
    "    # 03.00-Introduction-to-Pandas.ipynb\n",
    "    # 03.01-Introducing-Pandas-Objects.ipynb\n",
    "    # 03.02-Data-Indexing-and-Selection.ipynb\n",
    "    # 03.03-Operations-in-Pandas.ipynb\n",
    "    # 03.04-Missing-Values.ipynb\n",
    "    # 03.05-Hierarchical-Indexing.ipynb\n",
    "    # 03.06-Concat-And-Append.ipynb\n",
    "    # 03.07-Merge-and-Join.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "00cc3466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mType:\u001b[39m        module\n",
      "\u001b[31mString form:\u001b[39m <module 'pandas' from '/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/__init__.py'>\n",
      "\u001b[31mFile:\u001b[39m        /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/__init__.py\n",
      "\u001b[31mSource:\u001b[39m     \n",
      "\u001b[38;5;28;01mfrom\u001b[39;00m __future__ \u001b[38;5;28;01mimport\u001b[39;00m annotations\n",
      "\n",
      "\u001b[38;5;28;01mimport\u001b[39;00m os\n",
      "\u001b[38;5;28;01mimport\u001b[39;00m warnings\n",
      "\n",
      "__docformat__ = \u001b[33m\"restructuredtext\"\u001b[39m\n",
      "\n",
      "\u001b[38;5;66;03m# Let users know if they're missing any of our hard dependencies\u001b[39;00m\n",
      "_hard_dependencies = (\u001b[33m\"numpy\"\u001b[39m, \u001b[33m\"pytz\"\u001b[39m, \u001b[33m\"dateutil\"\u001b[39m)\n",
      "_missing_dependencies = []\n",
      "\n",
      "\u001b[38;5;28;01mfor\u001b[39;00m _dependency \u001b[38;5;28;01min\u001b[39;00m _hard_dependencies:\n",
      "    \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "        __import__(_dependency)\n",
      "    \u001b[38;5;28;01mexcept\u001b[39;00m ImportError \u001b[38;5;28;01mas\u001b[39;00m _e:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "        _missing_dependencies.append(f\"{_dependency}: {_e}\")\n",
      "\n",
      "\u001b[38;5;28;01mif\u001b[39;00m _missing_dependencies:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "    \u001b[38;5;28;01mraise\u001b[39;00m ImportError(\n",
      "        \u001b[33m\"Unable to import required dependencies:\\n\"\u001b[39m + \u001b[33m\"\\n\"\u001b[39m.join(_missing_dependencies)\n",
      "    )\n",
      "\u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n",
      "\n",
      "\u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "    \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n",
      "    \u001b[38;5;28;01mfrom\u001b[39;00m pandas.compat \u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "        is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev,  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n",
      "    )\n",
      "\u001b[38;5;28;01mexcept\u001b[39;00m ImportError \u001b[38;5;28;01mas\u001b[39;00m _err:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "    _module = _err.name\n",
      "    \u001b[38;5;28;01mraise\u001b[39;00m ImportError(\n",
      "        f\"C extension: {_module} not built. If you want to import \"\n",
      "        \u001b[33m\"pandas from the source directory, you may need to run \"\u001b[39m\n",
      "        \u001b[33m\"'python setup.py build_ext' to build the C extensions first.\"\u001b[39m\n",
      "    ) \u001b[38;5;28;01mfrom\u001b[39;00m _err\n",
      "\n",
      "\u001b[38;5;28;01mfrom\u001b[39;00m pandas._config \u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "    get_option,\n",
      "    set_option,\n",
      "    reset_option,\n",
      "    describe_option,\n",
      "    option_context,\n",
      "    options,\n",
      ")\n",
      "\n",
      "\u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n",
      "\u001b[38;5;28;01mimport\u001b[39;00m pandas.core.config_init  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n",
      "\n",
      "\u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.api \u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "    \u001b[38;5;66;03m# dtype\u001b[39;00m\n",
      "    ArrowDtype,\n",
      "    Int8Dtype,\n",
      "    Int16Dtype,\n",
      "    Int32Dtype,\n",
      "    Int64Dtype,\n",
      "    UInt8Dtype,\n",
      "    UInt16Dtype,\n",
      "    UInt32Dtype,\n",
      "    UInt64Dtype,\n",
      "    Float32Dtype,\n",
      "    Float64Dtype,\n",
      "    CategoricalDtype,\n",
      "    PeriodDtype,\n",
      "    IntervalDtype,\n",
      "    DatetimeTZDtype,\n",
      "    StringDtype,\n",
      "    BooleanDtype,\n",
      "    \u001b[38;5;66;03m# missing\u001b[39;00m\n",
      "    NA,\n",
      "    isna,\n",
      "    isnull,\n",
      "    notna,\n",
      "    notnull,\n",
      "    \u001b[38;5;66;03m# indexes\u001b[39;00m\n",
      "    Index,\n",
      "    CategoricalIndex,\n",
      "    RangeIndex,\n",
      "    MultiIndex,\n",
      "    IntervalIndex,\n",
      "    TimedeltaIndex,\n",
      "    DatetimeIndex,\n",
      "    PeriodIndex,\n",
      "    IndexSlice,\n",
      "    \u001b[38;5;66;03m# tseries\u001b[39;00m\n",
      "    NaT,\n",
      "    Period,\n",
      "    period_range,\n",
      "    Timedelta,\n",
      "    timedelta_range,\n",
      "    Timestamp,\n",
      "    date_range,\n",
      "    bdate_range,\n",
      "    Interval,\n",
      "    interval_range,\n",
      "    DateOffset,\n",
      "    \u001b[38;5;66;03m# conversion\u001b[39;00m\n",
      "    to_numeric,\n",
      "    to_datetime,\n",
      "    to_timedelta,\n",
      "    \u001b[38;5;66;03m# misc\u001b[39;00m\n",
      "    Flags,\n",
      "    Grouper,\n",
      "    factorize,\n",
      "    unique,\n",
      "    value_counts,\n",
      "    NamedAgg,\n",
      "    array,\n",
      "    Categorical,\n",
      "    set_eng_float_format,\n",
      "    Series,\n",
      "    DataFrame,\n",
      ")\n",
      "\n",
      "\u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.dtypes.dtypes \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n",
      "\n",
      "\u001b[38;5;28;01mfrom\u001b[39;00m pandas.tseries.api \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "\u001b[38;5;28;01mfrom\u001b[39;00m pandas.tseries \u001b[38;5;28;01mimport\u001b[39;00m offsets\n",
      "\n",
      "\u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.computation.api \u001b[38;5;28;01mimport\u001b[39;00m eval\n",
      "\n",
      "\u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.api \u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "    concat,\n",
      "    lreshape,\n",
      "    melt,\n",
      "    wide_to_long,\n",
      "    merge,\n",
      "    merge_asof,\n",
      "    merge_ordered,\n",
      "    crosstab,\n",
      "    pivot,\n",
      "    pivot_table,\n",
      "    get_dummies,\n",
      "    from_dummies,\n",
      "    cut,\n",
      "    qcut,\n",
      ")\n",
      "\n",
      "\u001b[38;5;28;01mfrom\u001b[39;00m pandas \u001b[38;5;28;01mimport\u001b[39;00m api, arrays, errors, io, plotting, tseries\n",
      "\u001b[38;5;28;01mfrom\u001b[39;00m pandas \u001b[38;5;28;01mimport\u001b[39;00m testing\n",
      "\u001b[38;5;28;01mfrom\u001b[39;00m pandas.util._print_versions \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n",
      "\n",
      "\u001b[38;5;28;01mfrom\u001b[39;00m pandas.io.api \u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "    \u001b[38;5;66;03m# excel\u001b[39;00m\n",
      "    ExcelFile,\n",
      "    ExcelWriter,\n",
      "    read_excel,\n",
      "    \u001b[38;5;66;03m# parsers\u001b[39;00m\n",
      "    read_csv,\n",
      "    read_fwf,\n",
      "    read_table,\n",
      "    \u001b[38;5;66;03m# pickle\u001b[39;00m\n",
      "    read_pickle,\n",
      "    to_pickle,\n",
      "    \u001b[38;5;66;03m# pytables\u001b[39;00m\n",
      "    HDFStore,\n",
      "    read_hdf,\n",
      "    \u001b[38;5;66;03m# sql\u001b[39;00m\n",
      "    read_sql,\n",
      "    read_sql_query,\n",
      "    read_sql_table,\n",
      "    \u001b[38;5;66;03m# misc\u001b[39;00m\n",
      "    read_clipboard,\n",
      "    read_parquet,\n",
      "    read_orc,\n",
      "    read_feather,\n",
      "    read_gbq,\n",
      "    read_html,\n",
      "    read_xml,\n",
      "    read_json,\n",
      "    read_stata,\n",
      "    read_sas,\n",
      "    read_spss,\n",
      ")\n",
      "\n",
      "\u001b[38;5;28;01mfrom\u001b[39;00m pandas.io.json._normalize \u001b[38;5;28;01mimport\u001b[39;00m json_normalize\n",
      "\n",
      "\u001b[38;5;28;01mfrom\u001b[39;00m pandas.util._tester \u001b[38;5;28;01mimport\u001b[39;00m test\n",
      "\n",
      "\u001b[38;5;66;03m# use the closest tagged version if possible\u001b[39;00m\n",
      "_built_with_meson = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "    \u001b[38;5;28;01mfrom\u001b[39;00m pandas._version_meson \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# pyright: ignore [reportMissingImports]\u001b[39;00m\n",
      "        __version__,\n",
      "        __git_version__,\n",
      "    )\n",
      "\n",
      "    _built_with_meson = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[38;5;28;01mexcept\u001b[39;00m ImportError:\n",
      "    \u001b[38;5;28;01mfrom\u001b[39;00m pandas._version \u001b[38;5;28;01mimport\u001b[39;00m get_versions\n",
      "\n",
      "    v = get_versions()\n",
      "    __version__ = v.get(\u001b[33m\"closest-tag\"\u001b[39m, v[\u001b[33m\"version\"\u001b[39m])\n",
      "    __git_version__ = v.get(\u001b[33m\"full-revisionid\"\u001b[39m)\n",
      "    \u001b[38;5;28;01mdel\u001b[39;00m get_versions, v\n",
      "\n",
      "\u001b[38;5;66;03m# GH#55043 - deprecation of the data_manager option\u001b[39;00m\n",
      "\u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"PANDAS_DATA_MANAGER\"\u001b[39m \u001b[38;5;28;01min\u001b[39;00m os.environ:\n",
      "    warnings.warn(\n",
      "        \u001b[33m\"The env variable PANDAS_DATA_MANAGER is set. The data_manager option is \"\u001b[39m\n",
      "        \u001b[33m\"deprecated and will be removed in a future version. Only the BlockManager \"\u001b[39m\n",
      "        \u001b[33m\"will be available. Unset this environment variable to silence this warning.\"\u001b[39m,\n",
      "        FutureWarning,\n",
      "        stacklevel=\u001b[32m2\u001b[39m,\n",
      "    )\n",
      "\n",
      "\u001b[38;5;28;01mdel\u001b[39;00m warnings, os\n",
      "\n",
      "\u001b[38;5;66;03m# module level doc-string\u001b[39;00m\n",
      "__doc__ = \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33mpandas - a powerful data analysis and manipulation library for Python\u001b[39m\n",
      "\u001b[33m=====================================================================\u001b[39m\n",
      "\n",
      "\u001b[33m**pandas** is a Python package providing fast, flexible, and expressive data\u001b[39m\n",
      "\u001b[33mstructures designed to make working with \"relational\" or \"labeled\" data both\u001b[39m\n",
      "\u001b[33measy and intuitive. It aims to be the fundamental high-level building block for\u001b[39m\n",
      "\u001b[33mdoing practical, **real world** data analysis in Python. Additionally, it has\u001b[39m\n",
      "\u001b[33mthe broader goal of becoming **the most powerful and flexible open source data\u001b[39m\n",
      "\u001b[33manalysis / manipulation tool available in any language**. It is already well on\u001b[39m\n",
      "\u001b[33mits way toward this goal.\u001b[39m\n",
      "\n",
      "\u001b[33mMain Features\u001b[39m\n",
      "\u001b[33m-------------\u001b[39m\n",
      "\u001b[33mHere are just a few of the things that pandas does well:\u001b[39m\n",
      "\n",
      "\u001b[33m  - Easy handling of missing data in floating point as well as non-floating\u001b[39m\n",
      "\u001b[33m    point data.\u001b[39m\n",
      "\u001b[33m  - Size mutability: columns can be inserted and deleted from DataFrame and\u001b[39m\n",
      "\u001b[33m    higher dimensional objects\u001b[39m\n",
      "\u001b[33m  - Automatic and explicit data alignment: objects can be explicitly aligned\u001b[39m\n",
      "\u001b[33m    to a set of labels, or the user can simply ignore the labels and let\u001b[39m\n",
      "\u001b[33m    `Series`, `DataFrame`, etc. automatically align the data for you in\u001b[39m\n",
      "\u001b[33m    computations.\u001b[39m\n",
      "\u001b[33m  - Powerful, flexible group by functionality to perform split-apply-combine\u001b[39m\n",
      "\u001b[33m    operations on data sets, for both aggregating and transforming data.\u001b[39m\n",
      "\u001b[33m  - Make it easy to convert ragged, differently-indexed data in other Python\u001b[39m\n",
      "\u001b[33m    and NumPy data structures into DataFrame objects.\u001b[39m\n",
      "\u001b[33m  - Intelligent label-based slicing, fancy indexing, and subsetting of large\u001b[39m\n",
      "\u001b[33m    data sets.\u001b[39m\n",
      "\u001b[33m  - Intuitive merging and joining data sets.\u001b[39m\n",
      "\u001b[33m  - Flexible reshaping and pivoting of data sets.\u001b[39m\n",
      "\u001b[33m  - Hierarchical labeling of axes (possible to have multiple labels per tick).\u001b[39m\n",
      "\u001b[33m  - Robust IO tools for loading data from flat files (CSV and delimited),\u001b[39m\n",
      "\u001b[33m    Excel files, databases, and saving/loading data from the ultrafast HDF5\u001b[39m\n",
      "\u001b[33m    format.\u001b[39m\n",
      "\u001b[33m  - Time series-specific functionality: date range generation and frequency\u001b[39m\n",
      "\u001b[33m    conversion, moving window statistics, date shifting and lagging.\u001b[39m\n",
      "\u001b[33m\"\"\"\u001b[39m\n",
      "\n",
      "\u001b[38;5;66;03m# Use __all__ to let type checkers know what is part of the public API.\u001b[39;00m\n",
      "\u001b[38;5;66;03m# Pandas is not (yet) a py.typed library: the public API is determined\u001b[39;00m\n",
      "\u001b[38;5;66;03m# based on the documentation.\u001b[39;00m\n",
      "__all__ = [\n",
      "    \u001b[33m\"ArrowDtype\"\u001b[39m,\n",
      "    \u001b[33m\"BooleanDtype\"\u001b[39m,\n",
      "    \u001b[33m\"Categorical\"\u001b[39m,\n",
      "    \u001b[33m\"CategoricalDtype\"\u001b[39m,\n",
      "    \u001b[33m\"CategoricalIndex\"\u001b[39m,\n",
      "    \u001b[33m\"DataFrame\"\u001b[39m,\n",
      "    \u001b[33m\"DateOffset\"\u001b[39m,\n",
      "    \u001b[33m\"DatetimeIndex\"\u001b[39m,\n",
      "    \u001b[33m\"DatetimeTZDtype\"\u001b[39m,\n",
      "    \u001b[33m\"ExcelFile\"\u001b[39m,\n",
      "    \u001b[33m\"ExcelWriter\"\u001b[39m,\n",
      "    \u001b[33m\"Flags\"\u001b[39m,\n",
      "    \u001b[33m\"Float32Dtype\"\u001b[39m,\n",
      "    \u001b[33m\"Float64Dtype\"\u001b[39m,\n",
      "    \u001b[33m\"Grouper\"\u001b[39m,\n",
      "    \u001b[33m\"HDFStore\"\u001b[39m,\n",
      "    \u001b[33m\"Index\"\u001b[39m,\n",
      "    \u001b[33m\"IndexSlice\"\u001b[39m,\n",
      "    \u001b[33m\"Int16Dtype\"\u001b[39m,\n",
      "    \u001b[33m\"Int32Dtype\"\u001b[39m,\n",
      "    \u001b[33m\"Int64Dtype\"\u001b[39m,\n",
      "    \u001b[33m\"Int8Dtype\"\u001b[39m,\n",
      "    \u001b[33m\"Interval\"\u001b[39m,\n",
      "    \u001b[33m\"IntervalDtype\"\u001b[39m,\n",
      "    \u001b[33m\"IntervalIndex\"\u001b[39m,\n",
      "    \u001b[33m\"MultiIndex\"\u001b[39m,\n",
      "    \u001b[33m\"NA\"\u001b[39m,\n",
      "    \u001b[33m\"NaT\"\u001b[39m,\n",
      "    \u001b[33m\"NamedAgg\"\u001b[39m,\n",
      "    \u001b[33m\"Period\"\u001b[39m,\n",
      "    \u001b[33m\"PeriodDtype\"\u001b[39m,\n",
      "    \u001b[33m\"PeriodIndex\"\u001b[39m,\n",
      "    \u001b[33m\"RangeIndex\"\u001b[39m,\n",
      "    \u001b[33m\"Series\"\u001b[39m,\n",
      "    \u001b[33m\"SparseDtype\"\u001b[39m,\n",
      "    \u001b[33m\"StringDtype\"\u001b[39m,\n",
      "    \u001b[33m\"Timedelta\"\u001b[39m,\n",
      "    \u001b[33m\"TimedeltaIndex\"\u001b[39m,\n",
      "    \u001b[33m\"Timestamp\"\u001b[39m,\n",
      "    \u001b[33m\"UInt16Dtype\"\u001b[39m,\n",
      "    \u001b[33m\"UInt32Dtype\"\u001b[39m,\n",
      "    \u001b[33m\"UInt64Dtype\"\u001b[39m,\n",
      "    \u001b[33m\"UInt8Dtype\"\u001b[39m,\n",
      "    \u001b[33m\"api\"\u001b[39m,\n",
      "    \u001b[33m\"array\"\u001b[39m,\n",
      "    \u001b[33m\"arrays\"\u001b[39m,\n",
      "    \u001b[33m\"bdate_range\"\u001b[39m,\n",
      "    \u001b[33m\"concat\"\u001b[39m,\n",
      "    \u001b[33m\"crosstab\"\u001b[39m,\n",
      "    \u001b[33m\"cut\"\u001b[39m,\n",
      "    \u001b[33m\"date_range\"\u001b[39m,\n",
      "    \u001b[33m\"describe_option\"\u001b[39m,\n",
      "    \u001b[33m\"errors\"\u001b[39m,\n",
      "    \u001b[33m\"eval\"\u001b[39m,\n",
      "    \u001b[33m\"factorize\"\u001b[39m,\n",
      "    \u001b[33m\"get_dummies\"\u001b[39m,\n",
      "    \u001b[33m\"from_dummies\"\u001b[39m,\n",
      "    \u001b[33m\"get_option\"\u001b[39m,\n",
      "    \u001b[33m\"infer_freq\"\u001b[39m,\n",
      "    \u001b[33m\"interval_range\"\u001b[39m,\n",
      "    \u001b[33m\"io\"\u001b[39m,\n",
      "    \u001b[33m\"isna\"\u001b[39m,\n",
      "    \u001b[33m\"isnull\"\u001b[39m,\n",
      "    \u001b[33m\"json_normalize\"\u001b[39m,\n",
      "    \u001b[33m\"lreshape\"\u001b[39m,\n",
      "    \u001b[33m\"melt\"\u001b[39m,\n",
      "    \u001b[33m\"merge\"\u001b[39m,\n",
      "    \u001b[33m\"merge_asof\"\u001b[39m,\n",
      "    \u001b[33m\"merge_ordered\"\u001b[39m,\n",
      "    \u001b[33m\"notna\"\u001b[39m,\n",
      "    \u001b[33m\"notnull\"\u001b[39m,\n",
      "    \u001b[33m\"offsets\"\u001b[39m,\n",
      "    \u001b[33m\"option_context\"\u001b[39m,\n",
      "    \u001b[33m\"options\"\u001b[39m,\n",
      "    \u001b[33m\"period_range\"\u001b[39m,\n",
      "    \u001b[33m\"pivot\"\u001b[39m,\n",
      "    \u001b[33m\"pivot_table\"\u001b[39m,\n",
      "    \u001b[33m\"plotting\"\u001b[39m,\n",
      "    \u001b[33m\"qcut\"\u001b[39m,\n",
      "    \u001b[33m\"read_clipboard\"\u001b[39m,\n",
      "    \u001b[33m\"read_csv\"\u001b[39m,\n",
      "    \u001b[33m\"read_excel\"\u001b[39m,\n",
      "    \u001b[33m\"read_feather\"\u001b[39m,\n",
      "    \u001b[33m\"read_fwf\"\u001b[39m,\n",
      "    \u001b[33m\"read_gbq\"\u001b[39m,\n",
      "    \u001b[33m\"read_hdf\"\u001b[39m,\n",
      "    \u001b[33m\"read_html\"\u001b[39m,\n",
      "    \u001b[33m\"read_json\"\u001b[39m,\n",
      "    \u001b[33m\"read_orc\"\u001b[39m,\n",
      "    \u001b[33m\"read_parquet\"\u001b[39m,\n",
      "    \u001b[33m\"read_pickle\"\u001b[39m,\n",
      "    \u001b[33m\"read_sas\"\u001b[39m,\n",
      "    \u001b[33m\"read_spss\"\u001b[39m,\n",
      "    \u001b[33m\"read_sql\"\u001b[39m,\n",
      "    \u001b[33m\"read_sql_query\"\u001b[39m,\n",
      "    \u001b[33m\"read_sql_table\"\u001b[39m,\n",
      "    \u001b[33m\"read_stata\"\u001b[39m,\n",
      "    \u001b[33m\"read_table\"\u001b[39m,\n",
      "    \u001b[33m\"read_xml\"\u001b[39m,\n",
      "    \u001b[33m\"reset_option\"\u001b[39m,\n",
      "    \u001b[33m\"set_eng_float_format\"\u001b[39m,\n",
      "    \u001b[33m\"set_option\"\u001b[39m,\n",
      "    \u001b[33m\"show_versions\"\u001b[39m,\n",
      "    \u001b[33m\"test\"\u001b[39m,\n",
      "    \u001b[33m\"testing\"\u001b[39m,\n",
      "    \u001b[33m\"timedelta_range\"\u001b[39m,\n",
      "    \u001b[33m\"to_datetime\"\u001b[39m,\n",
      "    \u001b[33m\"to_numeric\"\u001b[39m,\n",
      "    \u001b[33m\"to_pickle\"\u001b[39m,\n",
      "    \u001b[33m\"to_timedelta\"\u001b[39m,\n",
      "    \u001b[33m\"tseries\"\u001b[39m,\n",
      "    \u001b[33m\"unique\"\u001b[39m,\n",
      "    \u001b[33m\"value_counts\"\u001b[39m,\n",
      "    \u001b[33m\"wide_to_long\"\u001b[39m,\n",
      "]"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "pandas.__version__\n",
    "import pandas as pd\n",
    "pd??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "aba4e9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.) (0, 0.) (0, 0.)]\n",
      "5 (5,) 1 int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index([3, 0, 0, 1, 2], dtype='int64')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = pd.Series([0.25, 0.5, 0.75, 1.0])\n",
    "data\n",
    "\n",
    "data.values\n",
    "data[1]\n",
    "data[1:3]\n",
    "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
    "                 index = ['a', 'b', 'c', 'd'])\n",
    "data\n",
    "data['b']\n",
    "\n",
    "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
    "                 index = [2, 5, 3, 7])\n",
    "data\n",
    "data[5]\n",
    "\n",
    "population_dict = {'California': 38332521,\n",
    "                   'Texas': 26448193,\n",
    "                   'New York': 19651127,\n",
    "                   'Florida': 19552860,\n",
    "                   'Illinois': 12882135}\n",
    "\n",
    "population = pd.Series(population_dict)\n",
    "population\n",
    "population['California']\n",
    "population['California':'Illinois']\n",
    "\n",
    "pd.Series([2, 4, 6])\n",
    "pd.Series({2:'a', 1:'b', 3:'c'})\n",
    "pd.Series({2:'a', 1:'b', 3:'c'}, index = [3, 2])\n",
    "\n",
    "area_dict = {'California': 423967, 'Texas': 695662, 'New York': 141297,\n",
    "             'Florida': 170312, 'Illinois': 149995}\n",
    "area = pd.Series(area_dict)\n",
    "area\n",
    "\n",
    "states = pd.DataFrame({'population': population,\n",
    "                       'area': area})\n",
    "states\n",
    "states.index\n",
    "states.columns\n",
    "states['area']\n",
    "pd.DataFrame(population, columns = ['population'])\n",
    "\n",
    "data = [{'a': i, 'b': 2 * i} \n",
    "        for i in range(21)]\n",
    "pd.DataFrame(data)\n",
    "\n",
    "pd.DataFrame([{'a': 1, 'b': 2}, {'b': 3, 'c': 4}])\n",
    "\n",
    "pd.DataFrame({'population': population, 'area': area})\n",
    "\n",
    "pd.DataFrame(np.random.rand(3, 2),\n",
    "             columns = ['foo', 'bar'],\n",
    "             index = ['a', 'b', 'c'])\n",
    "\n",
    "A = np.zeros(3, dtype=[('A', 'i8'), ('B', 'f8')]);\n",
    "print(A)\n",
    "pd.DataFrame(A)\n",
    "\n",
    "ind = pd.Index([2, 3, 5, 7, 11])\n",
    "ind\n",
    "ind[1]\n",
    "ind[::2]\n",
    "print(ind.size, ind.shape, ind.ndim, ind.dtype)\n",
    "indA = pd.Index([1, 3, 5, 7, 9])\n",
    "indB = pd.Index([2, 3, 5, 6, 11])\n",
    "indA & indB\n",
    "indA | indB\n",
    "indA ^ indB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3752c64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>pop</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>141297.0</td>\n",
       "      <td>19651127.0</td>\n",
       "      <td>139.076746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>170312.0</td>\n",
       "      <td>19552860.0</td>\n",
       "      <td>114.806121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              area         pop     density\n",
       "New York  141297.0  19651127.0  139.076746\n",
       "Florida   170312.0  19552860.0  114.806121"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
    "index = ['a', 'b', 'c', 'd'])\n",
    "data\n",
    "\n",
    "data['b']\n",
    "'a' in data # bool statement\n",
    "\n",
    "data.items() # <zip at 0x117165200>\n",
    "data.keys() # Index(['a', 'b', 'c', 'd'], dtype='object')\n",
    "list(data.items()) # [('a', 0.25), ('b', 0.5), ('c', 0.75), ('d', 1.0)]\n",
    "# data['e'] # Notice, this returns an error as 'e' is not included\n",
    "\n",
    "data['e'] = 1.25 # Adds 'e'\n",
    "data\n",
    "\n",
    "data['a':'c']\n",
    "data[0:2]\n",
    "data[(data > 0.3) & (data < 0.8)]\n",
    "data[['a','e']]\n",
    "\n",
    "data = pd.Series(['a', 'b', 'c'],\n",
    "                 index = [1, 3, 5])\n",
    "data\n",
    "data[1]\n",
    "data[1:3]\n",
    "data.loc[1]\n",
    "data.loc[3]\n",
    "data.loc[5]\n",
    "data.loc[1:3]\n",
    "data.iloc[1:3]\n",
    "\n",
    "area = pd.Series({'California': 423967, 'Texas': 695662,\n",
    "                  'New York': 141297, 'Florida': 170312,\n",
    "                  'Illinois': 149995})\n",
    "pop = pd.Series({'California': 38332521, 'Texas': 26448193,\n",
    "                 'New York': 19651127, 'Florida': 19552860,\n",
    "                 'Illinois': 12882135})\n",
    "data = pd.DataFrame({'area':area,'pop':pop})\n",
    "data\n",
    "data['area']\n",
    "data.area\n",
    "data.area is data['area']   # True\n",
    "data.pop is data['pop'] # False\n",
    "# data['pop'] = z # Is better than data.pop = z\n",
    "\n",
    "data['density'] = data['pop'] / data['area']\n",
    "data.columns\n",
    "data['density']\n",
    "data\n",
    "data.values\n",
    "\n",
    "data = np.transpose(data); data\n",
    "data = data.T;data\n",
    "\n",
    "data.values[0]\n",
    "data['area']\n",
    "data.iloc[:3, :2]\n",
    "data.loc[:'Illinois', :'pop']\n",
    "data.loc[data.density > 100, ['pop', 'density']]\n",
    "data.loc[data.density < 100, ['pop', 'density']]\n",
    "data.iloc[0, 2] = 90\n",
    "data\n",
    "\n",
    "data['Florida':'Illinois']\n",
    "data[1:3]\n",
    "data[data.density > 100]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0dc4e10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A =\n",
      "0    2\n",
      "1    4\n",
      "2    6\n",
      "dtype: int64\n",
      "\n",
      "B =\n",
      "1    1\n",
      "2    3\n",
      "3    5\n",
      "dtype: int64\n",
      "\n",
      "A + B =\n",
      "0    NaN\n",
      "1    5.0\n",
      "2    9.0\n",
      "3    NaN\n",
      "dtype: float64\n",
      "\n",
      "A.add(B, fill_value = 0) = \n",
      "0    2.0\n",
      "1    5.0\n",
      "2    9.0\n",
      "3    5.0\n",
      "dtype: float64\n",
      "\n",
      "A =\n",
      "   A   B\n",
      "0  1  11\n",
      "1  5   1\n",
      "\n",
      "B =\n",
      "   B  A  C\n",
      "0  4  0  9\n",
      "1  5  8  0\n",
      "2  9  2  6\n",
      "\n",
      "A + B (no fill_value) =\n",
      "      A     B   C\n",
      "0   1.0  15.0 NaN\n",
      "1  13.0   6.0 NaN\n",
      "2   NaN   NaN NaN\n",
      "\n",
      "A + B (fill_value = 0) =\n",
      "      A     B    C\n",
      "0   1.0  15.0  9.0\n",
      "1  13.0   6.0  0.0\n",
      "2   2.0   9.0  6.0\n",
      "4.5\n",
      "\n",
      "A - A[0] =\n",
      "[[ 0  0  0  0]\n",
      " [-1 -2  2  4]\n",
      " [ 3 -7  1  4]]\n",
      "   Q  R  S  T\n",
      "0  3  8  2  4\n",
      "1  2  6  4  8\n",
      "2  6  1  3  8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Q   R    S   T\n",
       "0  0.0 NaN  0.0 NaN\n",
       "1 -1.0 NaN  2.0 NaN\n",
       "2  3.0 NaN  1.0 NaN"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "ser = pd.Series(rng.randint(0,10, 4))\n",
    "\n",
    "df = pd.DataFrame(rng.randint(0, 10, (3, 4)),\n",
    "                  columns = ['A', 'B', 'C', 'D'])\n",
    "\n",
    "df\n",
    "\n",
    "np.exp(ser)\n",
    "np.sin(df * np.pi / 4)\n",
    "np.exp(df)\n",
    "\n",
    "area = pd.Series({'Alaska': 1723337, 'Texas': 695662,\n",
    "                  'California': 423967}, name = 'area')\n",
    "population = pd.Series({'California': 38332521, 'Texas': 26448193,\n",
    "                        'New York': 19651127}, name = 'population')\n",
    "population / area\n",
    "\n",
    "A = pd.Series([2, 4, 6], index = [0, 1, 2])\n",
    "B = pd.Series([1, 3, 5], index = [1, 2, 3])\n",
    "print(\"\\nA =\")\n",
    "print(A)\n",
    "\n",
    "print(\"\\nB =\")\n",
    "print(B)\n",
    "\n",
    "print(\"\\nA + B =\")\n",
    "print(A+B)\n",
    "\n",
    "print(\"\\nA.add(B, fill_value = 0) = \")\n",
    "print(A.add(B, fill_value = 0))\n",
    "\n",
    "A = pd.DataFrame(rng.randint(0, 20, (2, 2)),\n",
    "                 columns = list('AB'))\n",
    "print('\\nA =')\n",
    "print(A)\n",
    "\n",
    "B = pd.DataFrame(rng.randint(0, 10, (3, 3)),\n",
    "                 columns=list('BAC'))\n",
    "print('\\nB =')\n",
    "print(B)\n",
    "\n",
    "print('\\nA + B (no fill_value) =')\n",
    "print(A + B)\n",
    "\n",
    "print('\\nA + B (fill_value = 0) =')\n",
    "print(A.add(B, fill_value = 0))\n",
    "\n",
    "fill = A.stack().mean()\n",
    "print(fill)\n",
    "A.add(B, fill_value = fill)\n",
    "\n",
    "A = rng.randint(10, size =(3, 4))\n",
    "print('\\nA - A[0] =')\n",
    "print(A - A[0])\n",
    "\n",
    "df = pd.DataFrame(A, columns = list('QRST'))\n",
    "print(df)\n",
    "df - df.iloc[0]\n",
    "df.subtract(df['R'], axis = 0)\n",
    "\n",
    "halfrow = df.iloc[0, ::2]\n",
    "halfrow\n",
    "\n",
    "df - halfrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "39aa287d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype = object\n",
      "dtype = int\n",
      "707 μs ± 79.5 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nn/rjk_sthj67g1rcv7qxd8_14m0000gn/T/ipykernel_70262/1605124372.py:51: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data.fillna(method = 'ffill')\n",
      "/var/folders/nn/rjk_sthj67g1rcv7qxd8_14m0000gn/T/ipykernel_70262/1605124372.py:52: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data.fillna(method = 'bfill')\n",
      "/var/folders/nn/rjk_sthj67g1rcv7qxd8_14m0000gn/T/ipykernel_70262/1605124372.py:55: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method = 'ffill', axis = 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3\n",
       "0  1.0  1.0  2.0  2.0\n",
       "1  2.0  3.0  5.0  5.0\n",
       "2  NaN  4.0  6.0  6.0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "vals1 = np.array([1, None, 3, 4])\n",
    "vals1\n",
    "for dtype in ['object', 'int']:\n",
    "    print('dtype =', dtype)\n",
    "%timeit np.arange(1E6, dtype=dtype).sum\n",
    "# vals1.sum() :: Notice: TypeError: unsupported operand type(s) for +: 'int' and 'NoneType'\n",
    "\n",
    "vals2 = np.array([1, np.nan, 3, 4])\n",
    "vals2.dtype\n",
    "\n",
    "1 + np.nan  # nan\n",
    "0 * np.nan  # nan\n",
    "\n",
    "vals2.sum(), vals2.min(), vals2.max()   # (np.float64(nan), np.float64(nan), np.float64(nan))\n",
    "\n",
    "np.nansum(vals2), np.nanmin(vals2), np.nanmax(vals2) # (np.float64(8.0), np.float64(1.0), np.float64(4.0))\n",
    "\n",
    "pd.Series([1, np.nan, 2, None])\n",
    "\n",
    "x = pd.Series(range(2), dtype = int)\n",
    "x\n",
    "x[0] = None\n",
    "x\n",
    "\n",
    "data = pd.Series([1, np.nan, 'hello', None])\n",
    "data.isnull()\n",
    "data.notnull()\n",
    "data[data.notnull()]\n",
    "\n",
    "data.dropna()\n",
    "\n",
    "df = pd.DataFrame([[1, np.nan, 2],\n",
    "                   [2, 3, 5],\n",
    "                   [np.nan, 4, 6]])\n",
    "df\n",
    "df.dropna()\n",
    "df.dropna(axis = 'columns')\n",
    "df[3] = np.nan\n",
    "df\n",
    "df.dropna(axis = 'columns', how = 'all')\n",
    "df.dropna(axis = 'rows', thresh = 3)\n",
    "\n",
    "data = pd.Series([1, np.nan, 2, None, 3], index = list('abcde'))\n",
    "data\n",
    "\n",
    "# fill.na methods\n",
    "data.fillna(0)\n",
    "data.fillna(method = 'ffill')\n",
    "data.fillna(method = 'bfill')\n",
    "\n",
    "df\n",
    "df.fillna(method = 'ffill', axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d765b393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pop =\n",
      " (California, 2000)    33871648\n",
      "(California, 2010)    37253956\n",
      "(New York, 2000)      18976457\n",
      "(New York, 2010)      19378102\n",
      "(Texas, 2000)         20851820\n",
      "(Texas, 2010)         25145561\n",
      "dtype: int64\n",
      "\n",
      "pop  =\n",
      " California  2000    33871648\n",
      "            2010    37253956\n",
      "New York    2000    18976457\n",
      "            2010    19378102\n",
      "Texas       2000    20851820\n",
      "            2010    25145561\n",
      "dtype: int64\n",
      "\n",
      "pop_df =   \n",
      "                 2000      2010\n",
      "California  33871648  37253956\n",
      "New York    18976457  19378102\n",
      "Texas       20851820  25145561\n",
      "\n",
      "pop_df.stack() =   \n",
      " California  2000    33871648\n",
      "            2010    37253956\n",
      "New York    2000    18976457\n",
      "            2010    19378102\n",
      "Texas       2000    20851820\n",
      "            2010    25145561\n",
      "dtype: int64\n",
      "\n",
      "pop_df (including under18's and total)  \n",
      "    =\n",
      "                     total  under18\n",
      "California 2000  33871648  9267089\n",
      "           2010  37253956  9284094\n",
      "New York   2000  18976457  4687374\n",
      "           2010  19378102  4318033\n",
      "Texas      2000  20851820  5906301\n",
      "           2010  25145561  6879014\n",
      "\n",
      "f_u18.unstack()  =\n",
      "                 2000      2010\n",
      "California  0.273594  0.249211\n",
      "New York    0.247010  0.222831\n",
      "Texas       0.283251  0.273568\n",
      "\n",
      "df =   \n",
      "         data1     data2\n",
      "a 1  0.673161  0.380759\n",
      "  2  0.812594  0.563769\n",
      "b 1  0.893200  0.863079\n",
      "  2  0.927449  0.510025\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "index = [('California', 2000), ('California', 2010),\n",
    "         ('New York', 2000), ('New York', 2010),\n",
    "         ('Texas', 2000), ('Texas', 2010)]\n",
    "\n",
    "populations = [33871648, 37253956,\n",
    "               18976457, 19378102,\n",
    "               20851820, 25145561]\n",
    "\n",
    "pop = pd.Series(populations, index = index)\n",
    "print('pop =\\n', pop)\n",
    "\n",
    "pop[('California', 2010):('Texas', 2000)]\n",
    "pop[[i for i in pop.index if i[1] == 2010]]\n",
    "\n",
    "index = pd.MultiIndex.from_tuples(index)\n",
    "index\n",
    "\n",
    "pop = pop.reindex(index)\n",
    "print('\\npop  =\\n', pop)\n",
    "\n",
    "pop[:, 2000]\n",
    "pop[:, 2010]\n",
    "\n",
    "pop_df = pop.unstack()\n",
    "print('\\npop_df =   \\n', pop_df)\n",
    "\n",
    "print('\\npop_df.stack() =   \\n', pop_df.stack())\n",
    "\n",
    "pop_df = pd.DataFrame({'total': pop,\n",
    "                       'under18':[9267089, 9284094,\n",
    "                                   4687374, 4318033,\n",
    "                                   5906301, 6879014]})\n",
    "\n",
    "print('\\npop_df (including under18\\'s and total)  \\n    =\\n', pop_df)\n",
    "\n",
    "f_u18 = pop_df['under18'] / pop_df['total']\n",
    "print('\\nf_u18.unstack()  =\\n', f_u18.unstack())\n",
    "\n",
    "df = pd.DataFrame(np.random.rand(4, 2),\n",
    "                  index = [['a', 'a', 'b', 'b'], [1, 2, 1, 2]],\n",
    "                  columns = ['data1', 'data2'])\n",
    "print('\\ndf =   \\n', df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d80c07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state       year\n",
       "California  2000    33871648\n",
       "            2010    37253956\n",
       "Texas       2010    25145561\n",
       "dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {('California', 2000): 33871648,\n",
    "        ('California', 2010): 37253956,\n",
    "        ('Texas', 2000): 20851820,\n",
    "        ('Texas', 2010): 25145561,\n",
    "        ('New York', 2000): 18976457,\n",
    "        ('New York', 2010): 19378102}\n",
    "data = pd.Series(data)\n",
    "data = data.unstack()\n",
    "data\n",
    "\n",
    "pd.MultiIndex.from_arrays([['a', 'a', 'b', 'b'], [1, 2, 1, 2]])\n",
    "pd.MultiIndex.from_tuples([('a', 1), ('a', 2), ('b', 1), ('b', 2)])\n",
    "pd.MultiIndex.from_product([['a', 'b'], [1, 2]])\n",
    "\n",
    "pop.index.names = ['state', 'year']\n",
    "pop\n",
    "pop[pop > 22000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "73d48c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "health_data  =   \n",
      " subject      Bob       Guido         Sue      \n",
      "type          HR  Temp    HR  Temp    HR  Temp\n",
      "year visit                                    \n",
      "2013 1      54.0  38.1  29.0  36.6  38.0  38.1\n",
      "     2      30.0  38.2  41.0  35.4  27.0  37.9\n",
      "2014 1      51.0  37.7  45.0  36.8  39.0  37.0\n",
      "     2      40.0  37.9  21.0  37.3  47.0  37.0\n",
      "\n",
      "health_data['Guido']  =\n",
      " type          HR  Temp\n",
      "year visit            \n",
      "2013 1      29.0  36.6\n",
      "     2      41.0  35.4\n",
      "2014 1      45.0  36.8\n",
      "     2      21.0  37.3\n",
      "\n",
      "health_data['Guido', 'HR']  =\n",
      " year  visit\n",
      "2013  1        29.0\n",
      "      2        41.0\n",
      "2014  1        45.0\n",
      "      2        21.0\n",
      "Name: (Guido, HR), dtype: float64\n",
      "\n",
      "health_data.iloc[:2,:2] =\n",
      " subject      Bob      \n",
      "type          HR  Temp\n",
      "year visit            \n",
      "2013 1      54.0  38.1\n",
      "     2      30.0  38.2\n",
      "\n",
      "health_data.loc[:, ('Bob', 'HR')]    \n",
      "    =\n",
      " year  visit\n",
      "2013  1        54.0\n",
      "      2        30.0\n",
      "2014  1        51.0\n",
      "      2        40.0\n",
      "Name: (Bob, HR), dtype: float64\n",
      "\n",
      "health_data.loc[idx[:, 1], idx[:, 'HR']]\n",
      "   =\n",
      " subject      Bob Guido   Sue\n",
      "type          HR    HR    HR\n",
      "year visit                  \n",
      "2013 1      54.0  29.0  38.0\n",
      "2014 1      51.0  45.0  39.0\n",
      "\n",
      "pop.unstack(level = 0) =\n",
      " state  California  New York     Texas\n",
      "year                                 \n",
      "2000     33871648  18976457  20851820\n",
      "2010     37253956  19378102  25145561\n",
      "\n",
      "pop.unstack(level = 1) =\n",
      " year            2000      2010\n",
      "state                         \n",
      "California  33871648  37253956\n",
      "New York    18976457  19378102\n",
      "Texas       20851820  25145561\n",
      "\n",
      "pop.unstack().stack  =\n",
      " state       year\n",
      "California  2000    33871648\n",
      "            2010    37253956\n",
      "New York    2000    18976457\n",
      "            2010    19378102\n",
      "Texas       2000    20851820\n",
      "            2010    25145561\n",
      "dtype: int64\n",
      "\n",
      "data_mean    =\n",
      " subject  type\n",
      "Bob      HR      43.750\n",
      "         Temp    37.975\n",
      "Guido    HR      34.000\n",
      "         Temp    36.525\n",
      "Sue      HR      37.750\n",
      "         Temp    37.500\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "index = pd.MultiIndex.from_product([[2013, 2014], [1, 2]],\n",
    "                                   names=['year', 'visit'])\n",
    "columns = pd.MultiIndex.from_product([['Bob', 'Guido', 'Sue'], ['HR', 'Temp']],\n",
    "                                     names=['subject', 'type'])\n",
    "\n",
    "data = np.round(np.random.randn(4, 6), 1)\n",
    "data[:, ::2] *= 10\n",
    "data += 37\n",
    "\n",
    "health_data = pd.DataFrame(data, index=index, columns=columns)\n",
    "print('\\nhealth_data  =   \\n', health_data)\n",
    "\n",
    "print('\\nhealth_data[\\'Guido\\']  =\\n', health_data['Guido'])\n",
    "print('\\nhealth_data[\\'Guido\\', \\'HR\\']  =\\n', health_data['Guido', 'HR'])\n",
    "print('\\nhealth_data.iloc[:2,:2] =\\n',health_data.iloc[:2, :2])\n",
    "print('\\nhealth_data.loc[:, (\\'Bob\\', \\'HR\\')]    \\n    =\\n', health_data.loc[:, ('Bob', 'HR')])\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "print('\\nhealth_data.loc[idx[:, 1], idx[:, \\'HR\\']]\\n   =\\n', health_data.loc[idx[:, 1], idx[:, 'HR']])\n",
    "\n",
    "index = pd.MultiIndex.from_product([['a', 'c', 'b'], [1, 2]])\n",
    "data = pd.Series(np.random.rand(6), index = index)\n",
    "data.index.names = ['char', 'int']\n",
    "data\n",
    "\n",
    "data = data.sort_index()\n",
    "data\n",
    "print('\\npop.unstack(level = 0) =\\n', pop.unstack(level = 0))\n",
    "print('\\npop.unstack(level = 1) =\\n', pop.unstack(level = 1))\n",
    "print('\\npop.unstack().stack  =\\n', pop.unstack().stack())\n",
    "\n",
    "pop_flat = pop.reset_index(name = 'population')\n",
    "pop_flat\n",
    "pop_flat.set_index(['state', 'year'])\n",
    "\n",
    "health_data\n",
    "data_mean = health_data.mean()\n",
    "print('\\ndata_mean    =\\n', data_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22ab9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def make_df(cols, ind):\n",
    "    \"\"\"Quickly make a DataFrame\"\"\"\n",
    "    data = {c: [str(c) + str(i) for i in ind]\n",
    "            for c in cols}\n",
    "    return pd.DataFrame(data, ind)\n",
    "\n",
    "make_df('ABC', range(3))\n",
    "\n",
    "class display(object):\n",
    "    \"\"\"Display HTML representation of multiple objects\"\"\"\n",
    "    template = \"\"\"<div style = \"float: left, padding: 10px;\">\n",
    "    <p style = 'font-family:\"Courier New,\", Courier, monospace'>{0}</p>{1}\n",
    "    </div>\"\"\"\n",
    "    def __init__(self, *args):\n",
    "        self.args = args\n",
    "    \n",
    "    def _repr_html_(self):\n",
    "        return '\\n'.join(self.template.format(a, eval(a)._repr_html_())\n",
    "                         for a in self.args)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '\\n\\n'.join(a + '\\n' + repr(eval(a))\n",
    "                           for a in self.args)\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2bf4f61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError: Indexes have overlapping values: Index([0, 1], dtype='int64')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style = \"float: left, padding: 10px;\">\n",
       "    <p style = 'font-family:\"Courier New,\", Courier, monospace'>df5</p><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1</td>\n",
       "      <td>B1</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2</td>\n",
       "      <td>B2</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style = \"float: left, padding: 10px;\">\n",
       "    <p style = 'font-family:\"Courier New,\", Courier, monospace'>df6</p><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B3</td>\n",
       "      <td>C3</td>\n",
       "      <td>D3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B4</td>\n",
       "      <td>C4</td>\n",
       "      <td>D4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style = \"float: left, padding: 10px;\">\n",
       "    <p style = 'font-family:\"Courier New,\", Courier, monospace'>pd.concat([df5, df6], join = 'inner')</p><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B2</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B3</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B4</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df5\n",
       "    A   B   C\n",
       "1  A1  B1  C1\n",
       "2  A2  B2  C2\n",
       "\n",
       "df6\n",
       "    B   C   D\n",
       "3  B3  C3  D3\n",
       "4  B4  C4  D4\n",
       "\n",
       "pd.concat([df5, df6], join = 'inner')\n",
       "    B   C\n",
       "1  B1  C1\n",
       "2  B2  C2\n",
       "3  B3  C3\n",
       "4  B4  C4"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1, 2, 3]\n",
    "y = [4, 5, 6]\n",
    "z = [7, 8, 9]\n",
    "np.concatenate([x, y, z])\n",
    "\n",
    "x = [[1, 2],\n",
    "     [3, 4]]\n",
    "np. concatenate([x, x], axis = 0)\n",
    "np.concatenate([x, x], axis = 1)\n",
    "\n",
    "ser1 = pd.Series(['A', 'B', 'C'], index = [1, 2, 3])\n",
    "ser2 = pd.Series(['D', 'E', 'F'], index = [4, 5, 6])\n",
    "pd.concat([ser1, ser2])\n",
    "\n",
    "df1 = make_df('AB', [1, 2])\n",
    "df2 = make_df('AB', [3, 4])\n",
    "display('df1', 'df2', 'pd.concat([df1, df2])')\n",
    "\n",
    "df3 = make_df('AB', [0, 1])\n",
    "df4 = make_df('CD', [0, 1])\n",
    "display('df3', 'df4', \"pd.concat([df3, df4], axis = 1)\")\n",
    "\n",
    "x = make_df(cols = 'AB', ind = [0, 1])\n",
    "y = make_df(cols = 'AB', ind = [2, 3])\n",
    "y.index = x.index\n",
    "display('x', 'y', 'pd.concat([x, y])')\n",
    "\n",
    "try:\n",
    "    pd.concat([x, y], verify_integrity = True)\n",
    "except ValueError as e:\n",
    "    print(\"ValueError:\", e)\n",
    "\n",
    "display('x', 'y', 'pd.concat([x, y], ignore_index = True)')\n",
    "\n",
    "display('x', 'y', \"pd.concat([x, y], keys = ['x', 'y'])\")\n",
    "\n",
    "df5 = make_df('ABC', [1, 2])\n",
    "df6 = make_df('BCD', [3, 4])\n",
    "display('df5', 'df6', 'pd.concat([df5, df6])')\n",
    "\n",
    "display('df5', 'df6',\n",
    "        \"pd.concat([df5, df6], join = 'inner')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497f7385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style = \"float: left, padding: 10px;\">\n",
       "    <p style = 'font-family:\"Courier New,\", Courier, monospace'>df1a</p><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employee</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>Accounting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jake</th>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lisa</th>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sue</th>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style = \"float: left, padding: 10px;\">\n",
       "    <p style = 'font-family:\"Courier New,\", Courier, monospace'>df3</p><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style = \"float: left, padding: 10px;\">\n",
       "    <p style = 'font-family:\"Courier New,\", Courier, monospace'>pd.merge(df1a, df3, left_index=True, right_on='name')</p><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>name</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accounting</td>\n",
       "      <td>Bob</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>Jake</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>Lisa</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HR</td>\n",
       "      <td>Sue</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df1a\n",
       "                group\n",
       "employee             \n",
       "Bob        Accounting\n",
       "Jake      Engineering\n",
       "Lisa      Engineering\n",
       "Sue                HR\n",
       "\n",
       "df3\n",
       "   name  salary\n",
       "0   Bob   70000\n",
       "1  Jake   80000\n",
       "2  Lisa  120000\n",
       "3   Sue   90000\n",
       "\n",
       "pd.merge(df1a, df3, left_index=True, right_on='name')\n",
       "         group  name  salary\n",
       "0   Accounting   Bob   70000\n",
       "1  Engineering  Jake   80000\n",
       "2  Engineering  Lisa  120000\n",
       "3           HR   Sue   90000"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'group': ['Accounting', 'Engineering', 'Engineering', 'HR']})\n",
    "df2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Jake', 'Sue'],\n",
    "                    'hire_date': [2004, 2008, 2012, 2014]})\n",
    "display('df1', 'df2')\n",
    "df3 = pd.merge(df1, df2)\n",
    "df3\n",
    "df4 = pd.DataFrame({'group': ['Accounting', 'Engineering', 'HR'],\n",
    "                    'supervisor': ['Carly', 'Guido', 'Steve']})\n",
    "display('df3', 'df4', 'pd.merge(df3, df4)')\n",
    "df5 = pd.DataFrame({'group': ['Accounting', 'Accounting',\n",
    "                              'Engineering', 'Engineering', 'HR', 'HR'],\n",
    "                    'skills': ['math', 'spreadsheets', 'coding', 'linux',\n",
    "                               'spreadsheets', 'organization']})\n",
    "display('df1', 'df5', \"pd.merge(df1, df5)\")\n",
    "display('df1', 'df2', \"pd.merge(df1, df2, on='employee')\")\n",
    "df3 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'salary': [70000, 80000, 120000, 90000]})\n",
    "display('df1', 'df3', 'pd.merge(df1, df3, left_on=\"employee\", right_on=\"name\")')\n",
    "pd.merge(df1, df3, left_on=\"employee\", right_on=\"name\").drop('name', axis=1)\n",
    "\n",
    "df1a = df1.set_index('employee')\n",
    "df2a = df2.set_index('employee')\n",
    "\n",
    "display('df1a', 'df2a')\n",
    "display('df1a', 'df2a', \"pd.merge(df1a, df2a, left_index = True, right_index = True)\")\n",
    "display('df1a', 'df2a', 'df1a.join(df2a)')\n",
    "display('df1a', 'df3', \"pd.merge(df1a, df3, left_index=True, right_on='name')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa30f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style = \"float: left, padding: 10px;\">\n",
       "    <p style = 'font-family:\"Courier New,\", Courier, monospace'>df8</p><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style = \"float: left, padding: 10px;\">\n",
       "    <p style = 'font-family:\"Courier New,\", Courier, monospace'>df9</p><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>\n",
       "<div style = \"float: left, padding: 10px;\">\n",
       "    <p style = 'font-family:\"Courier New,\", Courier, monospace'>pd.merge(df8, df9, on=\"name\", suffixes=[\"_L\", \"_R\"])</p><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rank_L</th>\n",
       "      <th>rank_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sue</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    </div>"
      ],
      "text/plain": [
       "df8\n",
       "   name  rank\n",
       "0   Bob     1\n",
       "1  Jake     2\n",
       "2  Lisa     3\n",
       "3   Sue     4\n",
       "\n",
       "df9\n",
       "   name  rank\n",
       "0   Bob     3\n",
       "1  Jake     1\n",
       "2  Lisa     4\n",
       "3   Sue     2\n",
       "\n",
       "pd.merge(df8, df9, on=\"name\", suffixes=[\"_L\", \"_R\"])\n",
       "   name  rank_L  rank_R\n",
       "0   Bob       1       3\n",
       "1  Jake       2       1\n",
       "2  Lisa       3       4\n",
       "3   Sue       4       2"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = pd.DataFrame({'name': ['Peter', 'Paul', 'Mary'],\n",
    "                    'food': ['fish', 'beans', 'bread']},\n",
    "                   columns=['name', 'food'])\n",
    "df7 = pd.DataFrame({'name': ['Mary', 'Joseph'],\n",
    "                    'drink': ['wine', 'beer']},\n",
    "                   columns=['name', 'drink'])\n",
    "\n",
    "display('df6', 'df7', 'pd.merge(df6, df7)')\n",
    "\n",
    "pd.merge(df6, df7, how='inner')\n",
    "\n",
    "display('df6', 'df7', \"pd.merge(df6, df7, how='outer')\")\n",
    "display('df6', 'df7', \"pd.merge(df6, df7, how='left')\")\n",
    "\n",
    "df8 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'rank': [1, 2, 3, 4]})\n",
    "df9 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'rank': [3, 1, 4, 2]})\n",
    "\n",
    "display('df8', 'df9', 'pd.merge(df8, df9, on=\"name\")')\n",
    "display('df8', 'df9', 'pd.merge(df8, df9, on=\"name\", suffixes=[\"_L\", \"_R\"])')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7ac20725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 57935  100 57935    0     0   183k      0 --:--:-- --:--:-- --:--:--  184k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   835  100   835    0     0   3726      0 --:--:-- --:--:-- --:--:--  3744\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   872  100   872    0     0   3954      0 --:--:-- --:--:-- --:--:--  3963\n"
     ]
    }
   ],
   "source": [
    "# Following are shell commands to download the data\n",
    "!curl -O https://raw.githubusercontent.com/jakevdp/data-USstates/master/state-population.csv\n",
    "!curl -O https://raw.githubusercontent.com/jakevdp/data-USstates/master/state-areas.csv\n",
    "!curl -O https://raw.githubusercontent.com/jakevdp/data-USstates/master/state-abbrevs.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9beb96ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "South Dakota    10.583512\n",
       "North Dakota     9.537565\n",
       "Montana          6.736171\n",
       "Wyoming          5.768079\n",
       "Alaska           1.087509\n",
       "dtype: float64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop = pd.read_csv('state-population.csv')\n",
    "areas = pd.read_csv('state-areas.csv')\n",
    "abbrevs = pd.read_csv('state-abbrevs.csv')\n",
    "display('pop.head()', 'areas.head()', 'abbrevs.head()')\n",
    "\n",
    "merged = pd.merge(pop, abbrevs, how = 'outer',\n",
    "                  left_on = 'state/region', \n",
    "                  right_on = 'abbreviation')\n",
    "merged = merged.drop(columns='abbreviation')\n",
    "merged.head()\n",
    "merged.isnull().any()\n",
    "merged[merged['population'].isnull()].head()\n",
    "\n",
    "merged.loc[merged['state'].isnull(), 'state/region'].unique()\n",
    "\n",
    "merged.loc[merged['state/region'] == 'PR', 'state'] = 'Puerto Rico'\n",
    "merged.loc[merged['state/region'] == 'USA', 'state'] = 'United States'\n",
    "merged.isnull().any()\n",
    "\n",
    "final = pd.merge(merged, areas, on='state', how='left')\n",
    "final.head()\n",
    "final.isnull().any()\n",
    "final['state'][final['area (sq. mi)'].isnull()].unique()\n",
    "final.dropna(inplace=True)\n",
    "final.head()\n",
    "\n",
    "data2010 = final.query(\"year == 2010 & ages == 'total'\")\n",
    "data2010.head()\n",
    "data2010.set_index('state', inplace=True)\n",
    "density = data2010['population'] / data2010['area (sq. mi)']\n",
    "density.sort_values(ascending=False, inplace=True)\n",
    "density.head()\n",
    "density.tail()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
